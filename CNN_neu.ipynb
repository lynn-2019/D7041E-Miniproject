{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a172eaaf-68dd-443a-b268-d054fe5f26f6",
   "metadata": {},
   "source": [
    "## CNN Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087925e-e8d8-4e71-9489-8d9a68ac9324",
   "metadata": {},
   "source": [
    "## 1. Preprocessing\n",
    "### 1.1. Imports and load ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c17fb2c-ee77-4d5b-90d9-3ee2ed4d2570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Reintjes\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cad642c-b207-44fe-9ed1-409310cafa2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 23.7.4\n"
     ]
    }
   ],
   "source": [
    "!conda --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb25adf-5043-4ea5-9fdd-61572e3be7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "Ytrain = np.load('TrainGT_preprocessed.npy')\n",
    "Ytest = np.load('TestGT_preprocessed.npy')\n",
    "\n",
    "# Load data\n",
    "Xtrain = np.load('Trainpics_preprocessed.npy')\n",
    "Xtest = np.load('Testpics_preprocessed.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e69fa4-44c0-44b4-bee8-957d1a397ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain=Ytrain-1\n",
    "Ytest=Ytest-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceaeee6b-92ca-4ff4-a19f-323fad94e640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805,)\n",
      "(805, 7)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 7 \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print(Ytrain.shape)\n",
    "Ytrain = to_categorical(Ytrain, num_classes=num_classes)\n",
    "print(Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76409ab-0bbb-4f9c-bc3a-aef0a9b26a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "x = 60\n",
    "y = 45\n",
    "Xtrain=Xtrain.reshape(805,y,x,3)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(Xtrain, Ytrain)):\n",
    "    X_train_fold, X_val_fold = Xtrain[train_index], Xtrain[val_index]\n",
    "    Y_train_fold, Y_val_fold = Ytrain[train_index], Ytrain[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb31d4c-d8ab-4aa5-b409-28a6f94c2827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Reintjes\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Reintjes\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Reintjes\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Reintjes\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Reintjes\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "21/21 [==============================] - 3s 50ms/step - loss: 2.0132 - accuracy: 0.1429 - val_loss: 1.9442 - val_accuracy: 0.1615\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.9473 - accuracy: 0.1646 - val_loss: 1.9532 - val_accuracy: 0.1180\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.9493 - accuracy: 0.1429 - val_loss: 1.9450 - val_accuracy: 0.1366\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 1s 24ms/step - loss: 1.9460 - accuracy: 0.1460 - val_loss: 1.9460 - val_accuracy: 0.1304\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 0s 24ms/step - loss: 1.9459 - accuracy: 0.1460 - val_loss: 1.9463 - val_accuracy: 0.1304\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 0s 25ms/step - loss: 1.9459 - accuracy: 0.1460 - val_loss: 1.9466 - val_accuracy: 0.1304\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.9459 - accuracy: 0.1460 - val_loss: 1.9469 - val_accuracy: 0.1304\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.9458 - accuracy: 0.1460 - val_loss: 1.9469 - val_accuracy: 0.1304\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 1s 28ms/step - loss: 1.9457 - accuracy: 0.1460 - val_loss: 1.9472 - val_accuracy: 0.1304\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.9457 - accuracy: 0.1460 - val_loss: 1.9475 - val_accuracy: 0.1304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bcbe1da5d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define your CNN model\n",
    "def create_cnn_model(filters=16, kernel_size=(3, 3), pool_size=(2, 2), dense_units=64, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=(input_shape)))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create CNN model\n",
    "input_shape = (y, x, 3)  # Adjust these based on your data\n",
    "num_classes = Ytrain.shape[1]  # Adjust based on your problem\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "\n",
    "# Fit the model (assuming Xtrain and Ytrain are your training data)\n",
    "cnn_model.fit(X_train_fold, Y_train_fold,epochs=10,validation_data=(X_val_fold, Y_val_fold))\n",
    "\n",
    "# Continue with the rest of your code...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bec994-2082-4da5-a577-1f0482271d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cnn_model.evaluate(Xtest, Ytest, verbose=2)\n",
    "except Exception as e:\n",
    "    print(\"Fehler beim Auswerten des Modells:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef7aa737-03e2-4ee8-9ff7-2dd199a1f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245,)\n",
      "[1. 1. 4. 1. 1. 0. 1. 4. 1. 1. 1. 4. 3. 1. 3. 4. 1. 1. 4. 1. 1. 2. 4. 4.\n",
      " 0. 6. 1. 1. 1. 2. 6. 1. 1. 1. 1. 1. 4. 1. 1. 1. 2. 1. 1. 1. 1. 4. 4. 0.\n",
      " 0. 4. 4. 1. 1. 4. 3. 1. 1. 1. 1. 0. 3. 1. 2. 4. 0. 4. 5. 2. 0. 2. 6. 2.\n",
      " 4. 4. 4. 4. 0. 0. 4. 0. 0. 5. 0. 4. 0. 4. 4. 0. 4. 0. 4. 5. 3. 4. 2. 2.\n",
      " 4. 4. 4. 0. 4. 4. 4. 4. 2. 2. 4. 4. 2. 0. 0. 5. 3. 6. 0. 6. 3. 3. 2. 2.\n",
      " 0. 5. 0. 0. 0. 6. 6. 0. 0. 5. 6. 2. 6. 0. 0. 3. 0. 0. 0. 0. 5. 2. 0. 6.\n",
      " 2. 2. 0. 6. 3. 2. 0. 6. 3. 2. 6. 0. 2. 6. 2. 6. 2. 6. 2. 3. 2. 3. 3. 2.\n",
      " 3. 3. 5. 2. 3. 2. 2. 5. 5. 5. 2. 3. 2. 2. 3. 3. 2. 3. 5. 3. 2. 6. 2. 6.\n",
      " 3. 6. 5. 6. 5. 5. 3. 3. 3. 5. 3. 5. 3. 3. 3. 3. 5. 5. 3. 5. 6. 5. 3. 5.\n",
      " 6. 6. 3. 5. 3. 6. 5. 5. 5. 5. 5. 5. 6. 5. 6. 5. 5. 6. 5. 5. 6. 5. 6. 6.\n",
      " 6. 6. 6. 6. 6.]\n",
      "(245, 7)\n"
     ]
    }
   ],
   "source": [
    "print(Ytest.shape)\n",
    "print(Ytest)\n",
    "Ytest = to_categorical(Ytest, num_classes=num_classes)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc256d-7673-4a29-918e-55b9bcec8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(Xtest,  Ytest, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b978d-594f-4fb0-b8c3-307136c56cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred_probabilities=cnn_model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d973da-522a-4a78-91e9-d7c4926d7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "# Konvertiere die Wahrscheinlichkeiten in Klassenindizes\n",
    "Ytest_pred = np.argmax(Ytest_pred_probabilities, axis=1)\n",
    "# Drucke einzigartige Werte in Ytest_true und Ytest_pred\n",
    "print(\"Unique values in Ytest_true:\", np.unique(Ytest))\n",
    "print(\"Unique values in Ytest_pred:\", np.unique(Ytest_pred))\n",
    "\n",
    "# Drucke die Formen von Ytest_true und Ytest_pred\n",
    "print(\"Shape of Ytest_true:\", Ytest.shape)\n",
    "print(\"Shape of Ytest_pred:\", Ytest_pred.shape)\n",
    "\n",
    "# Berechne die Confusion Matrix\n",
    "Ytest_true=np.argmax(Ytest, axis=1)\n",
    "\n",
    "conf_matrix = confusion_matrix(Ytest_true, Ytest_pred)\n",
    "# Plotte die Confusion Matrix als Heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baa318-ddf6-4caf-9e78-af29d315bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
